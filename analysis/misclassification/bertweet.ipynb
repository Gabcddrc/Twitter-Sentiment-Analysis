{
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# BERTweet Misclassification Analysis"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Analyise validation tweets misclassified by BERTweet."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "import os\n",
                "import sys\n",
                "import re\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "from IPython.display import display\n",
                "\n",
                "sys.path.append(os.path.join(os.pardir, os.pardir, 'src'))\n",
                "from data_processing.loading import load_train_valid_data"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# Load original dataset to get correct labels.\n",
                "path_to_dataset = os.path.join(os.pardir, os.pardir, 'dataset')\n",
                "_, valid = load_train_valid_data(path_to_dataset)\n",
                "\n",
                "display(valid)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# Load BERTweet predictions generated while experimenting with the model.\n",
                "valid_predictions = pd.read_csv('bertweet_valid_predictions.csv', index_col='Id')\n",
                "\n",
                "# Change column names to fit with original dataset for easy joining.\n",
                "valid_predictions.index.name = 'id'\n",
                "valid_predictions.columns = ['prediction']\n",
                "\n",
                "display(valid_predictions)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# Join BERTweet classifications with original labels.\n",
                "valid_joint = valid.join(valid_predictions)\n",
                "\n",
                "# Filter correctly classified tweets.\n",
                "valid_correct = valid_joint[valid_joint['label'] == valid_joint['prediction']]\n",
                "\n",
                "# Filter misclassified tweets, i.e. where prediction is different from label.\n",
                "valid_misclass = valid_joint[valid_joint['label'] != valid_joint['prediction']]\n",
                "\n",
                "display(valid_correct)\n",
                "display(valid_misclass)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# Compute confusion matrix to see if one class is more frequently\n",
                "# misclassified.\n",
                "labels = ['positive', 'negative']\n",
                "\n",
                "num_valid_tweets = len(valid)\n",
                "\n",
                "num_true_positives = len(valid_correct[valid_correct['label'] == 1])\n",
                "num_false_positives = len(valid_misclass[valid_misclass['label'] == 1])\n",
                "\n",
                "num_true_negatives = len(valid_correct[valid_correct['label'] == -1])\n",
                "num_false_negatives = len(valid_misclass[valid_misclass['label'] == -1])\n",
                "\n",
                "confusion_matrix = np.array([\n",
                "    [num_true_positives, num_false_positives],\n",
                "    [num_false_negatives, num_true_negatives]\n",
                "]) / num_valid_tweets\n",
                "\n",
                "fig, ax = plt.subplots(figsize=((6,6)))\n",
                "im = ax.imshow(confusion_matrix)\n",
                "\n",
                "# Show all ticks and label with respective list entries.\n",
                "ax.set_xticks(np.arange(len(labels)))\n",
                "ax.set_yticks(np.arange(len(labels)))\n",
                "ax.set_xticklabels(labels)\n",
                "ax.set_yticklabels(labels)\n",
                "\n",
                "ax.set_xlabel('Predicted')\n",
                "ax.set_ylabel('True')\n",
                "\n",
                "# Loop over data dimensions and create text annotations.\n",
                "for i in range(len(labels)):\n",
                "    for j in range(len(labels)):\n",
                "        text = ax.text(j, i, f'{100 * confusion_matrix[i, j]:.2f}%',\n",
                "                       ha=\"center\", va=\"center\")\n",
                "\n",
                "ax.set_title(\"BERTweet Confusion Matrix\")\n",
                "fig.tight_layout()\n",
                "plt.show()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Misclassified Common Twitter Abbreviations\n",
                "\n",
                "Check to see if common Twitter abbreviations occur in the misclassified\n",
                "validation tweets with a frequency higher than their full text versions. If so,\n",
                "then this hints at BERTweet struggling with Twitter abbreviations, which would\n",
                "be ground for dictionary normalization with the full text versions.\n",
                "\n",
                "The candidates for Twitter abbreviations and their full versions are taken from:\n",
                "\n",
                "https://www.webopedia.com/reference/twitter-dictionary-guide/"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# Compute a dataframe with a summary of occurrences of different candidate\n",
                "# abbreviations and their full text counter parts.\n",
                "abbreviation_occur = []\n",
                "\n",
                "with open(\"normalization-dict-candidates.csv\", \"r\") as f:\n",
                "    for index, line in enumerate(f.readlines()):\n",
                "        if index == 0:\n",
                "            # Skip the header line.\n",
                "            continue\n",
                "\n",
                "        abbr, full = line.strip().split(\",\")\n",
                "        abbr_matcher = re.compile(\n",
                "            f\"(\\s+{abbr}\\s+)|(^{abbr}\\s+)|(\\s+{abbr}$)|(^{abbr}$)\"\n",
                "        )\n",
                "        full_matcher = re.compile(\n",
                "            f\"(\\s+{full}\\s+)|(^{full}\\s+)|(\\s+{full}$)|(^{full}$)\"\n",
                "        )\n",
                "\n",
                "        valid['abbr_occur'] = valid['tweet'].apply(\n",
                "            lambda tweet: len(abbr_matcher.findall(tweet))\n",
                "        )\n",
                "\n",
                "        valid_misclass['abbr_occur'] = valid_misclass['tweet'].apply(\n",
                "            lambda tweet: len(abbr_matcher.findall(tweet))\n",
                "        )\n",
                "\n",
                "        valid['full_occur'] = valid['tweet'].apply(\n",
                "            lambda tweet: len(full_matcher.findall(tweet))\n",
                "        )\n",
                "\n",
                "        valid_misclass['full_occur'] = valid_misclass['tweet'].apply(\n",
                "            lambda tweet: len(full_matcher.findall(tweet))\n",
                "        )\n",
                "\n",
                "        valid_abbr_occur = float(valid['abbr_occur'].sum())\n",
                "        misclass_abbr_occur = valid_misclass['abbr_occur'].sum()\n",
                "\n",
                "        valid_full_occur = float(valid['full_occur'].sum())\n",
                "        misclass_full_occur = valid_misclass['full_occur'].sum()\n",
                "\n",
                "        abbreviation_occur.append([\n",
                "            abbr,\n",
                "            misclass_abbr_occur,\n",
                "            valid_abbr_occur,\n",
                "            misclass_abbr_occur / valid_abbr_occur,\n",
                "            full,\n",
                "            misclass_full_occur,\n",
                "            valid_full_occur,\n",
                "            misclass_full_occur / valid_full_occur\n",
                "        ])\n",
                "\n",
                "del valid['abbr_occur']\n",
                "del valid['full_occur']\n",
                "del valid_misclass['abbr_occur']\n",
                "del valid_misclass['full_occur']\n",
                "\n",
                "abbreviation_occurrances = pd.DataFrame(\n",
                "    abbreviation_occur,\n",
                "    columns=[\n",
                "        'abbr',\n",
                "        'abbr_misclass_occur',\n",
                "        'abbr_valid_occur',\n",
                "        'abbr_error_rate',\n",
                "        'full',\n",
                "        'full_misclass_occur',\n",
                "        'full_valid_occur',\n",
                "        'full_error_rate'\n",
                "    ]\n",
                ")\n",
                "\n",
                "display(abbreviation_occurrances)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# Filter out the actual dictionary normalizations we would want to do based on\n",
                "# the misclassified data.\n",
                "dict_normalizations = abbreviation_occurrances.copy()\n",
                "\n",
                "# Remove abbreviations or full text versions that do not occur at all, as\n",
                "# we cannot possibly do a reasonable replacement.\n",
                "dict_normalizations = dict_normalizations[dict_normalizations['abbr_valid_occur'] != 0.0]\n",
                "dict_normalizations = dict_normalizations[dict_normalizations['full_valid_occur'] != 0.0]\n",
                "\n",
                "# Remove abbreviations or full text versions where both are below the\n",
                "# overall error rate, as there is no ground for replacement at this stage.\n",
                "misclass_error = len(valid_misclass) / float(len(valid))\n",
                "dict_normalizations = dict_normalizations[\n",
                "    (dict_normalizations['abbr_error_rate'] >= misclass_error) |\n",
                "    (dict_normalizations['full_error_rate'] >= misclass_error)\n",
                "]\n",
                "\n",
                "# Remove abbreviations that occur more frequently than their full text\n",
                "# counterparts. If the abbreviation occurs more frequently, then we would\n",
                "# actually be obfuscating the text.\n",
                "# Example: 'yolo' is in considerably higher use than 'you only live once'.\n",
                "dict_normalizations = dict_normalizations[\n",
                "    dict_normalizations['abbr_valid_occur'] <=\n",
                "    dict_normalizations['full_valid_occur']\n",
                "]\n",
                "\n",
                "# Finally, keep abbreviations that have higher error rate than their full text\n",
                "# counterparts so that they can be replaced.\n",
                "dict_normalizations = dict_normalizations[\n",
                "    dict_normalizations['abbr_error_rate'] >=\n",
                "    dict_normalizations['full_error_rate']\n",
                "]\n",
                "\n",
                "display(dict_normalizations)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# Store normalization dictionary for later use.\n",
                "normalization_dict = dict_normalizations[['abbr','full']]\n",
                "normalization_dict = normalization_dict.rename(columns={'abbr': 'abbreviation', 'full': 'full_text'})\n",
                "\n",
                "normalization_dict.to_csv('normalization-dict.csv', index=False)\n",
                "\n",
                "display(normalization_dict)"
            ],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}